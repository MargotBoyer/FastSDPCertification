import torch
import multiprocessing as mp
import concurrent.futures
from typing import List, Tuple
import numpy as np
import time


def solve_single_lp(args):
    """
    Worker function to solve a single LP problem

    Args:
        args: tuple containing (model, image, true_label, target_label, eps,
              compute_bounds_method, image_index, target_index)

    Returns:
        dict with results from the LP solve
    """
    (
        model,
        image,
        true_label,
        target_label,
        eps,
        compute_bounds_method,
        image_index,
        target_index,
    ) = args

    try:
        # Import inside worker to avoid pickling issues
        from solve import ClassicLP
        from bounds import compute_bounds_data

        # Compute bounds for this image and target
        L, U = compute_bounds_data(
            model,
            image,
            eps,
            model.n,
            model.K,
            method=compute_bounds_method,
        )
        print("Compute bounds of data : DONE")

        # Create and solve LP
        lp = ClassicLP(
            network=model,
            x=image.cpu().numpy(),
            ytrue=true_label,
            ytarget=target_label,
            epsilon=eps,
            L=L,
            U=U,
        )
        print("Creation of LP Attack : DONE")

        lp.solve()

        print("LP Attack solved : DONE")

        return {
            "image_index": image_index,
            "target_index": target_index,
            "target_label": target_label,
            "optimal_value": lp.get_optimal_value(),
            "adversarial_attack": lp.get_adversarial_attack(),
            "status": "success",
            "bounds_computed": True,
        }

    except Exception as e:
        return {
            "image_index": image_index,
            "target_index": target_index,
            "target_label": target_label,
            "optimal_value": 0.0,
            "adversarial_attack": None,
            "status": "error",
            "error": str(e),
            "bounds_computed": False,
        }


class LP_Attack_Multiprocessing:
    def __init__(
        self, model, num_classes, eps, compute_bounds_method, max_workers=None
    ):
        self.model = model
        self.num_classes = num_classes
        self.eps = eps
        self.compute_bounds_method = compute_bounds_method

        # With 64 cores, we can be aggressive with parallelization
        if max_workers is None:
            # Use most cores but leave a few for system processes
            self.max_workers = min(mp.cpu_count() - 4, 60)
        else:
            self.max_workers = max_workers

        print(f"Initialized with {self.max_workers} maximum workers")

    def forward(self, images, labels) -> Tuple[float, torch.Tensor]:
        """
        Generate adversarial images with maximum parallelization across images and classes.

        Args:
            images: Batch of images (torch.Tensor)
            labels: True labels of the images (torch.Tensor)

        Returns:
            loss_perturbation: Sum of all optimal values (float)
            adversarial_images: Adversarial images generated by the attack (torch.Tensor)
        """
        images = images.clone().detach()
        labels = labels.clone().detach()

        start_time = time.time()

        # Create all tasks (image, target_class combinations)
        tasks = []
        task_mapping = (
            {}
        )  # Map task_id to (image_idx, target_idx) for result reconstruction
        task_id = 0

        for img_idx in range(len(images)):
            for target_class in range(self.num_classes):
                if labels[img_idx] == target_class:
                    continue  # Skip same class

                task = (
                    self.model,
                    images[img_idx],
                    labels[img_idx].item(),
                    target_class,
                    self.eps,
                    self.compute_bounds_method,
                    img_idx,
                    target_class,
                )
                tasks.append(task)
                task_mapping[task_id] = (img_idx, target_class)
                task_id += 1

        total_tasks = len(tasks)
        print(
            f"Processing {len(images)} images Ã— {self.num_classes-1} target classes = {total_tasks} LP problems"
        )
        print(f"Using {self.max_workers} parallel workers")

        # Solve all LPs in parallel
        results = self._solve_parallel_with_progress(tasks)

        # Organize results
        loss_perturbation, adv_images = self._process_results(
            results, task_mapping, images, labels
        )

        end_time = time.time()
        print(f"Total parallel execution time: {end_time - start_time:.2f} seconds")
        print(
            f"Average time per LP: {(end_time - start_time) / total_tasks:.4f} seconds"
        )

        return loss_perturbation, adv_images

    def _solve_parallel_with_progress(self, tasks):
        """Solve tasks in parallel with progress reporting"""
        results = [None] * len(tasks)

        # Use ProcessPoolExecutor for better control and progress tracking
        with concurrent.futures.ProcessPoolExecutor(
            max_workers=self.max_workers
        ) as executor:
            # Submit all tasks
            future_to_idx = {
                executor.submit(solve_single_lp, task): idx
                for idx, task in enumerate(tasks)
            }

            completed = 0
            successful = 0
            failed = 0

            # Process completed tasks with progress updates
            for future in concurrent.futures.as_completed(future_to_idx):
                task_idx = future_to_idx[future]

                try:
                    result = future.result()
                    results[task_idx] = result

                    if result["status"] == "success":
                        successful += 1
                    else:
                        failed += 1

                    completed += 1

                    # Progress updates
                    if completed % 100 == 0:
                        progress = (completed / len(tasks)) * 100
                        print(
                            f"Progress: {completed}/{len(tasks)} ({progress:.1f}%) - "
                            f"Success: {successful}, Failed: {failed}"
                        )

                except Exception as e:
                    # Handle worker process errors
                    img_idx, target_idx = None, None
                    if task_idx < len(tasks):
                        img_idx = tasks[task_idx][6]  # image_index from task tuple
                        target_idx = tasks[task_idx][7]  # target_index from task tuple

                    results[task_idx] = {
                        "image_index": img_idx,
                        "target_index": target_idx,
                        "optimal_value": 0.0,
                        "adversarial_attack": None,
                        "status": "worker_error",
                        "error": str(e),
                    }
                    failed += 1
                    completed += 1

            print(
                f"Final results: {successful} successful, {failed} failed out of {len(tasks)} total"
            )

        return results

    def _process_results(self, results, task_mapping, images, labels):
        """Process and organize results into final format"""
        loss_perturbation = 0.0

        # Create a structured way to store adversarial images
        # Structure: adv_images[img_idx][target_class] = adversarial_image
        num_images = len(images)
        adv_images_dict = {}

        successful_count = 0
        failed_count = 0

        for task_id, result in enumerate(results):
            if result is None:
                continue

            img_idx = result["image_index"]
            target_idx = result["target_index"]

            if result["status"] == "success":
                loss_perturbation += result["optimal_value"]

                # Store adversarial image
                if img_idx not in adv_images_dict:
                    adv_images_dict[img_idx] = {}
                adv_images_dict[img_idx][target_idx] = result["adversarial_attack"]
                successful_count += 1

            else:
                failed_count += 1
                print(
                    f"Failed LP for image {img_idx}, target {target_idx}: "
                    f"{result.get('error', 'Unknown error')}"
                )

        # Convert to flat list (maintaining original order)
        adv_images_list = []
        for img_idx in range(num_images):
            for target_class in range(self.num_classes):
                if labels[img_idx] == target_class:
                    continue

                if (
                    img_idx in adv_images_dict
                    and target_class in adv_images_dict[img_idx]
                ):
                    adv_images_list.append(adv_images_dict[img_idx][target_class])
                else:
                    # Use original image as fallback for failed cases
                    adv_images_list.append(images[img_idx].cpu().numpy())

        # Convert to tensor
        adv_images = torch.tensor(
            adv_images_list, dtype=images.dtype, device=images.device
        )

        print(f"Generated {len(adv_images_list)} adversarial images")
        print(
            f"Success rate: {successful_count}/{successful_count + failed_count} "
            f"({100 * successful_count / (successful_count + failed_count):.1f}%)"
        )
        print(f"Adversarial images shape: {adv_images.shape}")

        return loss_perturbation, adv_images


class LP_Attack_BatchedParrallel:
    """
    Alternative implementation that processes images in batches to manage memory
    """

    def __init__(
        self,
        model,
        num_classes,
        eps,
        compute_bounds_method,
        max_workers=None,
        batch_size=8,
    ):
        self.model = model
        self.num_classes = num_classes
        self.eps = eps
        self.compute_bounds_method = compute_bounds_method
        self.max_workers = max_workers or min(mp.cpu_count() - 4, 60)
        self.batch_size = batch_size  # Process images in batches to manage memory

    def forward(self, images, labels) -> Tuple[float, torch.Tensor]:
        """Process images in batches to manage memory with 64 cores"""

        total_loss = 0.0
        all_adv_images = []

        # Process images in batches
        for batch_start in range(0, len(images), self.batch_size):
            batch_end = min(batch_start + self.batch_size, len(images))

            print(
                f"Processing batch {batch_start//self.batch_size + 1}: "
                f"images {batch_start}-{batch_end-1}"
            )

            batch_images = images[batch_start:batch_end]
            batch_labels = labels[batch_start:batch_end]

            # Use the high-performance attack for this batch
            attack = LP_Attack_Multiprocessing(
                self.model,
                self.num_classes,
                self.eps,
                self.compute_bounds_method,
                self.max_workers,
            )

            batch_loss, batch_adv = attack.forward(batch_images, batch_labels)

            total_loss += batch_loss
            all_adv_images.append(batch_adv)

        # Concatenate all adversarial images
        final_adv_images = torch.cat(all_adv_images, dim=0)

        return total_loss, final_adv_images


class LP_Attack_Optimized:
    def __init__(
        self,
        model,
        num_classes,
        eps,
        targeted: bool = False,
        norm: str = "inf",
        compute_bounds_method: str = "alpha-CROWN",
    ):
        self.model = model
        self.num_classes = num_classes
        self.eps = eps
        self.compute_bounds_method = compute_bounds_method
        self.targeted = targeted
        self.norm = norm

    def forward_max_performance(self, images, labels) -> Tuple[float, torch.Tensor]:
        """Use all 64 cores for maximum performance"""
        parallel_attack = LP_Attack_Multiprocessing(
            model=self.model,
            num_classes=self.num_classes,
            eps=self.eps,
            compute_bounds_method=self.compute_bounds_method,
            max_workers=60,  # Use 60 out of 64 cores
        )

        return parallel_attack.forward(images, labels)

    def forward_memory_conscious(self, images, labels) -> Tuple[float, torch.Tensor]:
        """Process in batches to manage memory with large datasets"""
        batched_attack = LP_Attack_BatchedParrallel(
            model=self.model,
            num_classes=self.num_classes,
            eps=self.eps,
            compute_bounds_method=self.compute_bounds_method,
            max_workers=60,
            batch_size=4,  # Process 4 images at a time
        )

        return batched_attack.forward(images, labels)

    # Recommended configuration for 64 cores:
    def forward(self, images, labels) -> Tuple[float, torch.Tensor]:
        """Optimized configuration for 64-core systems"""

        # Choose strategy based on input size
        num_total_tasks = len(images) * (self.num_classes - 1)

        if num_total_tasks > 1000:  # Large workload
            print("Using batched approach for large workload")
            return self.forward_memory_conscious(images, labels)
        else:  # Moderate workload
            print("Using maximum performance approach")
            return self.forward_max_performance(images, labels)
