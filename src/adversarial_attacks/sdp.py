import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.autograd import grad

from solve import SDP_attack
from bounds import compute_bounds_data


class SDPAttack:
    """
    Impléementation of the Linear Programming based attack.

    Args:
        model: the model to attack
        eps: pertubation ball radius
        random_start: if True, starts with a random perturbation, else starts with zero perturbationœ
        targeted: if True, performs a targeted attack (attacks a specific class), else performs an untargeted attack
        norm: Types of norm ('inf', '2', '1')
    """

    def __init__(
        self,
        model,
        num_classes,
        eps=0.3,
        norm="inf",
    ):
        self.model = model
        self.num_classes = num_classes
        self.eps = eps
        self.norm = norm

    def forward(self, images, labels):
        """
        Generate adversarial images using the SDP Program Based attack.

        Args:
            images: Batch of images (torch.Tensor)
            labels: True labels of the images (torch.Tensor)
            target_labels: Target labels for targeted attacks (torch.Tensor, optional)

        Returns:
            adversarial_images: Adversarial images generated by the attack (torch.Tensor)
        """
        images = images.clone().detach()
        labels = labels.clone().detach()

        bound = 0

        for ind in range(len(images)):
            for j in range(self.num_classes):
                if labels[ind] == j:
                    continue

                L, U = compute_bounds_data(
                    self.model,
                    images[ind],
                    self.eps,
                    self.model.n,
                    self.model.K,
                    method=self.compute_bounds_method,
                )
                print(f"len U : {[len(u) for u in U]}")
                print(f"len L : {[len(l) for l in L]}")
                print(
                    "Min U : ", [min(u) for u in U], "   max U : ", [max(u) for u in U]
                )
                print(
                    "Min L : ", [min(l) for l in L], "   max L : ", [max(l) for l in L]
                )

                sdp = SDP_attack(
                    network=self.model,
                    x=images[ind].cpu().numpy(),
                    ytrue=labels[ind].item(),
                    ytarget=j,
                    epsilon=self.eps,
                    L=L,
                    U=U,
                )
                bound += sdp.solve()

        return bound

    def _random_init(self, images):
        """Initialisation aléatoire de la perturbation"""
        if self.norm == "inf":
            delta = torch.empty_like(images).uniform_(-self.eps, self.eps)
        elif self.norm == "2":
            delta = torch.randn_like(images)
            delta = delta.view(delta.shape[0], -1)
            delta = delta / torch.norm(delta, dim=1, keepdim=True)
            delta = delta.view(images.shape)
            delta = delta * self.eps * torch.rand(images.shape[0], 1, 1, 1)
        elif self.norm == "1":
            delta = torch.randn_like(images)
            delta = delta.view(delta.shape[0], -1)
            delta = delta / torch.norm(delta, p=1, dim=1, keepdim=True)
            delta = delta.view(images.shape)
            delta = delta * self.eps * torch.rand(images.shape[0], 1, 1, 1)

        return delta

    def _project_linf(self, delta, eps):
        """Projection L-infinite"""
        return torch.clamp(delta, -eps, eps)

    def _project_l2(self, delta, eps):
        """Projection L2"""
        delta_flat = delta.view(delta.shape[0], -1)
        delta_norm = torch.norm(delta_flat, dim=1, keepdim=True)
        delta_flat = delta_flat / torch.max(
            delta_norm / eps, torch.ones_like(delta_norm)
        )
        return delta_flat.view(delta.shape)

    def _project_l1(self, delta, eps):
        """Projection L1"""
        delta_flat = delta.view(delta.shape[0], -1)
        delta_abs = torch.abs(delta_flat)
        delta_norm = torch.sum(delta_abs, dim=1, keepdim=True)

        # Si la norme est déjà <= eps, pas de projection nécessaire
        mask = delta_norm <= eps

        # Sinon, on projette
        delta_flat = delta_flat / torch.max(
            delta_norm / eps, torch.ones_like(delta_norm)
        )

        return delta_flat.view(delta.shape)
