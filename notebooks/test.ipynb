{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5afd7c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i1 = np.array([1, 5, 3, 4])\n",
    "num_m1 = np.array([1, 1, 1, 1])\n",
    "val1 = np.array([0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "i2 = np.array([2, 7, 8])\n",
    "num_m2 = np.array([1, 1, 1])\n",
    "val2 = np.array([1, 2, 3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "set(num_m1) == set(num_m2) and len(set(num_m1)) == 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29335639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = [4, 5, 6]\n",
    "list1.extend(list2)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbc86b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, 4, 2, 7, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(i1, i2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "951ed9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val : [0.2 0.4 0.6 0.3 0.6 0.9 0.4 0.8 1.2 0.5 1.  1.5]\n",
      "val .shape :      (12,)\n",
      "i : [2 7 8 2 7 8 2 7 8 2 7 8]\n",
      "j :  [1 1 1 5 5 5 3 3 3 4 4 4]\n",
      "num_m : [1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "val = vectorized_operations_example(val1, val2, np.multiply)\n",
    "val = val.flatten()\n",
    "print(\"val :\", val)\n",
    "i_j = vectorized_operations_example(i2, i1, np.meshgrid)\n",
    "i_j = np.array(i_j).flatten()\n",
    "print(\"val .shape :     \", val.shape)\n",
    "print(\"i :\", i_j[:val.shape[0]])\n",
    "print(\"j : \", i_j[val.shape[0]:])\n",
    "i = i_j[:val.shape[0]]\n",
    "j = i_j[val.shape[0]:]\n",
    "num_m = np.broadcast_to(num_m1[:, np.newaxis], (len(num_m1), len(num_m2))).flatten()\n",
    "print(\"num_m :\", num_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfcdad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.append(i, 2)\n",
    "j = np.append(j, 1)\n",
    "num_m = np.append(num_m, 1)\n",
    "val = np.append(val, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e64cddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : [2 7 8 2 7 8 2 7 8 2 7 8 2]\n",
      "j : [1 1 1 5 5 5 3 3 3 4 4 4 1]\n",
      "i : [2 7 8 5 7 8 3 7 8 4 7 8 2]\n",
      "j : [1 1 1 2 5 5 2 3 3 2 4 4 1]\n",
      "T1_red : [2 3 4 5 7 7 7 7 8 8 8 8]\n",
      "T2_red : [1 2 2 2 1 3 4 5 1 3 4 5]\n",
      "T3_red : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "T4_red : [99.2  0.4  0.5  0.3  0.4  0.8  1.   0.6  0.6  1.2  1.5  0.9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: T1, T2, T3, T4 are 1D arrays of the same length\n",
    "# Combine T1, T2, T3 into a structured array of tuples\n",
    "print(\"i :\", i)\n",
    "print(\"j :\", j)\n",
    "i_ = np.where(i > j , i, j)\n",
    "j_ = np.where(i > j , j, i)\n",
    "print(\"i :\", i_)\n",
    "print(\"j :\", j_)\n",
    "keys = np.stack((i_, j_, num_m), axis=-1)\n",
    "\n",
    "# Get unique keys and inverse indices\n",
    "unique_keys, inverse = np.unique(keys, axis=0, return_inverse=True)\n",
    "\n",
    "# Sum T4 values for each unique key\n",
    "summed_T4 = np.bincount(inverse, weights=val)\n",
    "\n",
    "# Split unique keys back into T1, T2, T3\n",
    "T1_red, T2_red, T3_red = unique_keys.T\n",
    "T4_red = summed_T4\n",
    "\n",
    "print(\"T1_red :\", T1_red)\n",
    "print(\"T2_red :\", T2_red)\n",
    "print(\"T3_red :\", T3_red)\n",
    "print(\"T4_red :\", T4_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "207f4a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "383cd2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 : [1 1 1 5 5 5 3 3 3 4 4 4]\n",
      "T2 : [6 7 8 6 7 8 6 7 8 6 7 8]\n",
      "val : [0.2 0.4 0.6 0.3 0.6 0.9 0.4 0.8 1.2 0.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "T1 = np.repeat(i1, len(i2))\n",
    "T2 = np.tile(i2, len(i1))\n",
    "val = np.repeat(val1, len(i2))* (np.tile(val2, len(i1)))\n",
    "\n",
    "print(\"T1 :\", T1)\n",
    "print(\"T2 :\", T2)\n",
    "print(\"val :\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e700c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ============ FASTER ALTERNATIVES ============\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "# ============ FASTER ALTERNATIVES ============\n",
    "\n",
    "def lazy_cartesian_iterator(T1, T2):\n",
    "    \"\"\"\n",
    "    FASTEST for sequential access - no memory allocation upfront.\n",
    "    Memory: O(1), Time per element: O(1)\n",
    "    \"\"\"\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            yield t1, t2\n",
    "\n",
    "def itertools_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Using itertools.product - very memory efficient.\n",
    "    \"\"\"\n",
    "    return itertools.product(T1, T2)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def numba_cartesian_fill(T1, T2, i1, i2):\n",
    "    \"\"\"\n",
    "    Numba-compiled version - much faster for large arrays.\n",
    "    Pre-allocate arrays and fill them with compiled code.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for i in range(len(T1)):\n",
    "        for j in range(len(T2)):\n",
    "            i1[idx] = T1[i]\n",
    "            i2[idx] = T2[j]\n",
    "            idx += 1\n",
    "\n",
    "def fast_cartesian_numba(T1, T2):\n",
    "    \"\"\"\n",
    "    Fastest for large arrays when you need materialized result.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    numba_cartesian_fill(T1, T2, i1, i2)\n",
    "    return i1, i2\n",
    "\n",
    "def broadcasting_indices(T1, T2):import numpy as np\n",
    "import itertools\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "# ============ FASTER ALTERNATIVES ============\n",
    "\n",
    "def lazy_cartesian_iterator(T1, T2):\n",
    "    \"\"\"\n",
    "    FASTEST for sequential access - no memory allocation upfront.\n",
    "    Memory: O(1), Time per element: O(1)\n",
    "    \"\"\"\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            yield t1, t2\n",
    "\n",
    "def itertools_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Using itertools.product - very memory efficient.\n",
    "    \"\"\"\n",
    "    return itertools.product(T1, T2)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def numba_cartesian_fill(T1, T2, i1, i2):\n",
    "    \"\"\"\n",
    "    Numba-compiled version - much faster for large arrays.\n",
    "    Pre-allocate arrays and fill them with compiled code.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for i in range(len(T1)):\n",
    "        for j in range(len(T2)):\n",
    "            i1[idx] = T1[i]\n",
    "            i2[idx] = T2[j]\n",
    "            idx += 1\n",
    "\n",
    "def fast_cartesian_numba(T1, T2):\n",
    "    \"\"\"\n",
    "    Fastest for large arrays when you need materialized result.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    numba_cartesian_fill(T1, T2, i1, i2)\n",
    "    return i1, i2\n",
    "\n",
    "def broadcasting_indices(T1, T2):\n",
    "    \"\"\"\n",
    "    Use broadcasting with indices - avoids copying data.\n",
    "    Most memory efficient when you can work with indices.\n",
    "    \"\"\"\n",
    "    i_indices = np.arange(len(T1))[:, None]\n",
    "    j_indices = np.arange(len(T2))[None, :]\n",
    "    \n",
    "    # Return indices that can be used to access T1 and T2\n",
    "    return i_indices + np.zeros_like(j_indices), j_indices + np.zeros_like(i_indices)\n",
    "\n",
    "def chunked_cartesian(T1, T2, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Process Cartesian product in chunks - memory efficient for huge arrays.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    for i in range(0, len(T1), chunk_size):\n",
    "        chunk_T1 = T1[i:i+chunk_size]\n",
    "        i1_chunk = np.repeat(chunk_T1, len(T2))\n",
    "        i2_chunk = np.tile(T2, len(chunk_T1))\n",
    "        yield i1_chunk, i2_chunk\n",
    "\n",
    "def meshgrid_view_based(T1, T2):\n",
    "    \"\"\"\n",
    "    Use meshgrid but delay flattening - work with 2D views when possible.\n",
    "    \"\"\"\n",
    "    mesh1, mesh2 = np.meshgrid(T1, T2, indexing='ij')\n",
    "    return mesh1, mesh2  # Return 2D arrays instead of flattening\n",
    "\n",
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "# ============ SPECIALIZED FAST IMPLEMENTATIONS ============\n",
    "\n",
    "def fast_cartesian_memoryview(T1, T2):\n",
    "    \"\"\"\n",
    "    Using memory views for even faster access (when using Cython/Numba).\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Manual filling (would be faster in Cython)\n",
    "    idx = 0\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            i1[idx] = t1\n",
    "            i2[idx] = t2\n",
    "            idx += 1\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "def preallocated_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Pre-allocate arrays with correct dtype for better performance.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    \n",
    "    # Pre-allocate with specific dtypes\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Use numpy operations on pre-allocated arrays\n",
    "    i1[:] = np.repeat(T1, len(T2))\n",
    "    i2[:] = np.tile(T2, len(T1))\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "# ============ BENCHMARKING ============\n",
    "\n",
    "def benchmark_all_methods(T1, T2, iterations=100):\n",
    "    \"\"\"\n",
    "    Benchmark all methods comprehensively.\n",
    "    \"\"\"\n",
    "    methods = [\n",
    "        (\"Standard repeat+tile\", lambda: (np.repeat(T1, len(T2)), np.tile(T2, len(T1)))),\n",
    "        (\"Numba compiled\", lambda: fast_cartesian_numba(T1, T2)),\n",
    "        (\"Pre-allocated\", lambda: preallocated_cartesian(T1, T2)),\n",
    "        (\"Memory view style\", lambda: fast_cartesian_memoryview(T1, T2)),\n",
    "        (\"Meshgrid+flatten\", lambda: [x.flatten() for x in np.meshgrid(T1, T2, indexing='ij')]),\n",
    "    ]\n",
    "    \n",
    "    print(f\"Benchmarking with T1 size: {len(T1)}, T2 size: {len(T2)}\")\n",
    "    print(f\"Output size: {len(T1) * len(T2)}, Iterations: {iterations}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, method in methods:\n",
    "        # Warmup for Numba\n",
    "        if \"Numba\" in name:\n",
    "            method()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(iterations):\n",
    "            result = method()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results[name] = elapsed / iterations\n",
    "        print(f\"{name:20}: {elapsed/iterations:.6f}s per call\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def memory_efficient_examples():\n",
    "    \"\"\"\n",
    "    Show memory-efficient alternatives for different use cases.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MEMORY-EFFICIENT ALTERNATIVES ===\")\n",
    "    \n",
    "    T1 = np.arange(1000)\n",
    "    T2 = np.arange(2000)\n",
    "    \n",
    "    print(f\"Input sizes: T1={len(T1)}, T2={len(T2)}\")\n",
    "    print(f\"Full Cartesian product would need: {len(T1) * len(T2) * 8 / 1e6:.1f} MB\")\n",
    "    \n",
    "    print(\"\\n1. Lazy iteration (zero upfront memory):\")\n",
    "    lazy_iter = lazy_cartesian_iterator(T1[:10], T2[:10])\n",
    "    print(\"   First 3 pairs:\", [next(lazy_iter) for _ in range(3)])\n",
    "    \n",
    "    print(\"\\n2. Chunked processing:\")\n",
    "    chunk_gen = chunked_cartesian(T1[:100], T2[:100], chunk_size=50)\n",
    "    first_chunk = next(chunk_gen)\n",
    "    print(f\"   First chunk size: {len(first_chunk[0])}\")\n",
    "    \n",
    "    print(\"\\n3. Broadcasting for direct computation:\")\n",
    "    # Example: compute sum of all pairs without storing pairs\n",
    "    sum_matrix = vectorized_operations_example(T1[:10], T2[:10], np.add)\n",
    "    print(f\"   Sum matrix shape: {sum_matrix.shape}\")\n",
    "    print(f\"   Memory saved: {100 * (1 - sum_matrix.nbytes / (len(T1[:10]) * len(T2[:10]) * 2 * 8)):.1f}%\")\n",
    "\n",
    "def speed_comparison_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate speed improvements with different array sizes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SPEED COMPARISON ===\")\n",
    "    \n",
    "    sizes = [(100, 100), (500, 200), (1000, 100)]\n",
    "    \n",
    "    for t1_size, t2_size in sizes:\n",
    "        print(f\"\\nArray sizes: T1={t1_size}, T2={t2_size}\")\n",
    "        T1 = np.arange(t1_size)\n",
    "        T2 = np.arange(t2_size)\n",
    "        \n",
    "        # Standard method\n",
    "        start = time.time()\n",
    "        i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "        std_time = time.time() - start\n",
    "        \n",
    "        # Numba method\n",
    "        start = time.time()\n",
    "        i1_numba, i2_numba = fast_cartesian_numba(T1, T2)\n",
    "        numba_time = time.time() - start\n",
    "        \n",
    "        # Verify results are identical\n",
    "        identical = np.array_equal(i1_std, i1_numba) and np.array_equal(i2_std, i2_numba)\n",
    "        speedup = std_time / numba_time if numba_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  Standard: {std_time:.6f}s\")\n",
    "        print(f\"  Numba:    {numba_time:.6f}s\")\n",
    "        print(f\"  Speedup:  {speedup:.1f}x\")\n",
    "        print(f\"  Results identical: {identical}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with small arrays first\n",
    "    T1 = [1, 2]\n",
    "    T2 = [3, 4, 5]\n",
    "    \n",
    "    print(\"=== TESTING WITH SMALL ARRAYS ===\")\n",
    "    print(f\"T1 = {T1}\")\n",
    "    print(f\"T2 = {T2}\")\n",
    "    \n",
    "    # Standard method\n",
    "    i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "    print(f\"\\nStandard result:\")\n",
    "    print(f\"i1 = {i1_std}\")\n",
    "    print(f\"i2 = {i2_std}\")\n",
    "    \n",
    "    # Fast numba method\n",
    "    i1_fast, i2_fast = fast_cartesian_numba(T1, T2)\n",
    "    print(f\"\\nNumba result:\")\n",
    "    print(f\"i1 = {i1_fast}\")\n",
    "    print(f\"i2 = {i2_fast}\")\n",
    "    \n",
    "    # Verify they're the same\n",
    "    print(f\"Results identical: {np.array_equal(i1_std, i1_fast) and np.array_equal(i2_std, i2_fast)}\")\n",
    "    \n",
    "    # Show lazy iteration\n",
    "    print(f\"\\nLazy iteration:\")\n",
    "    for i, (a, b) in enumerate(lazy_cartesian_iterator(T1, T2)):\n",
    "        print(f\"  Pair {i}: ({a}, {b})\")\n",
    "    \n",
    "    # Memory efficient examples\n",
    "    memory_efficient_examples()\n",
    "    \n",
    "    # Speed comparison\n",
    "    speed_comparison_demo()\n",
    "    \n",
    "    print(\"\\n=== RECOMMENDATIONS BY USE CASE ===\")\n",
    "    print(\"• Sequential access only: Use lazy_cartesian_iterator() - O(1) memory\")\n",
    "    print(\"• Large arrays, need full result: Use fast_cartesian_numba() - 2-10x faster\")\n",
    "    print(\"• Memory constrained: Use chunked_cartesian() - process in batches\")\n",
    "    print(\"• Direct operations: Use broadcasting - avoid materialization entirely\")\n",
    "    print(\"• Small arrays: Standard repeat+tile is fine\"\n",
    "    \"\"\"\n",
    "    Use broadcasting with indices - avoids copying data.\n",
    "    Most memory efficient when you can work with indices.\n",
    "    \"\"\"\n",
    "    i_indices = np.arange(len(T1))[:, None]\n",
    "    j_indices = np.arange(len(T2))[None, :]\n",
    "    \n",
    "    # Return indices that can be used to access T1 and T2\n",
    "    return i_indices + np.zeros_like(j_indices), j_indices + np.zeros_like(i_indices)\n",
    "\n",
    "def chunked_cartesian(T1, T2, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Process Cartesian product in chunks - memory efficient for huge arrays.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    for i in range(0, len(T1), chunk_size):\n",
    "        chunk_T1 = T1[i:i+chunk_size]\n",
    "        i1_chunk = np.repeat(chunk_T1, len(T2))\n",
    "        i2_chunk = np.tile(T2, len(chunk_T1))\n",
    "        yield i1_chunk, i2_chunk\n",
    "\n",
    "def meshgrid_view_based(T1, T2):\n",
    "    \"\"\"\n",
    "    Use meshgrid but delay flattening - work with 2D views when possible.\n",
    "    \"\"\"\n",
    "    mesh1, mesh2 = np.meshgrid(T1, T2, indexing='ij')\n",
    "    return mesh1, mesh2  # Return 2D arrays instead of flattening\n",
    "\n",
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "# ============ SPECIALIZED FAST IMPLEMENTATIONS ============\n",
    "\n",
    "def fast_cartesian_memoryview(T1, T2):\n",
    "    \"\"\"\n",
    "    Using memory views for even faster access (when using Cython/Numba).\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Manual filling (would be faster in Cython)\n",
    "    idx = 0\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            i1[idx] = t1\n",
    "            i2[idx] = t2\n",
    "            idx += 1\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "def preallocated_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Pre-allocate arrays with correct dtype for better performance.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    \n",
    "    # Pre-allocate with specific dtypes\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Use numpy operations on pre-allocated arrays\n",
    "    i1[:] = np.repeat(T1, len(T2))\n",
    "    i2[:] = np.tile(T2, len(T1))\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "# ============ BENCHMARKING ============\n",
    "\n",
    "def benchmark_all_methods(T1, T2, iterations=100):\n",
    "    \"\"\"\n",
    "    Benchmark all methods comprehensively.\n",
    "    \"\"\"\n",
    "    methods = [\n",
    "        (\"Standard repeat+tile\", lambda: (np.repeat(T1, len(T2)), np.tile(T2, len(T1)))),\n",
    "        (\"Numba compiled\", lambda: fast_cartesian_numba(T1, T2)),\n",
    "        (\"Pre-allocated\", lambda: preallocated_cartesian(T1, T2)),\n",
    "        (\"Memory view style\", lambda: fast_cartesian_memoryview(T1, T2)),\n",
    "        (\"Meshgrid+flatten\", lambda: [x.flatten() for x in np.meshgrid(T1, T2, indexing='ij')]),\n",
    "    ]\n",
    "    \n",
    "    print(f\"Benchmarking with T1 size: {len(T1)}, T2 size: {len(T2)}\")\n",
    "    print(f\"Output size: {len(T1) * len(T2)}, Iterations: {iterations}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, method in methods:\n",
    "        # Warmup for Numba\n",
    "        if \"Numba\" in name:\n",
    "            method()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(iterations):\n",
    "            result = method()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results[name] = elapsed / iterations\n",
    "        print(f\"{name:20}: {elapsed/iterations:.6f}s per call\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def memory_efficient_examples():\n",
    "    \"\"\"\n",
    "    Show memory-efficient alternatives for different use cases.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MEMORY-EFFICIENT ALTERNATIVES ===\")\n",
    "    \n",
    "    T1 = np.arange(1000)\n",
    "    T2 = np.arange(2000)\n",
    "    \n",
    "    print(f\"Input sizes: T1={len(T1)}, T2={len(T2)}\")\n",
    "    print(f\"Full Cartesian product would need: {len(T1) * len(T2) * 8 / 1e6:.1f} MB\")\n",
    "    \n",
    "    print(\"\\n1. Lazy iteration (zero upfront memory):\")\n",
    "    lazy_iter = lazy_cartesian_iterator(T1[:10], T2[:10])\n",
    "    print(\"   First 3 pairs:\", [next(lazy_iter) for _ in range(3)])\n",
    "    \n",
    "    print(\"\\n2. Chunked processing:\")\n",
    "    chunk_gen = chunked_cartesian(T1[:100], T2[:100], chunk_size=50)\n",
    "    first_chunk = next(chunk_gen)\n",
    "    print(f\"   First chunk size: {len(first_chunk[0])}\")\n",
    "    \n",
    "    print(\"\\n3. Broadcasting for direct computation:\")\n",
    "    # Example: compute sum of all pairs without storing pairs\n",
    "    sum_matrix = vectorized_operations_example(T1[:10], T2[:10], np.add)\n",
    "    print(f\"   Sum matrix shape: {sum_matrix.shape}\")\n",
    "    print(f\"   Memory saved: {100 * (1 - sum_matrix.nbytes / (len(T1[:10]) * len(T2[:10]) * 2 * 8)):.1f}%\")\n",
    "\n",
    "def speed_comparison_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate speed improvements with different array sizes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SPEED COMPARISON ===\")\n",
    "    \n",
    "    sizes = [(100, 100), (500, 200), (1000, 100)]\n",
    "    \n",
    "    for t1_size, t2_size in sizes:\n",
    "        print(f\"\\nArray sizes: T1={t1_size}, T2={t2_size}\")\n",
    "        T1 = np.arange(t1_size)\n",
    "        T2 = np.arange(t2_size)\n",
    "        \n",
    "        # Standard method\n",
    "        start = time.time()\n",
    "        i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "        std_time = time.time() - start\n",
    "        \n",
    "        # Numba method\n",
    "        start = time.time()\n",
    "        i1_numba, i2_numba = fast_cartesian_numba(T1, T2)\n",
    "        numba_time = time.time() - start\n",
    "        \n",
    "        # Verify results are identical\n",
    "        identical = np.array_equal(i1_std, i1_numba) and np.array_equal(i2_std, i2_numba)\n",
    "        speedup = std_time / numba_time if numba_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  Standard: {std_time:.6f}s\")\n",
    "        print(f\"  Numba:    {numba_time:.6f}s\")\n",
    "        print(f\"  Speedup:  {speedup:.1f}x\")\n",
    "        print(f\"  Results identical: {identical}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with small arrays first\n",
    "    T1 = [1, 2]\n",
    "    T2 = [3, 4, 5]\n",
    "    \n",
    "    print(\"=== TESTING WITH SMALL ARRAYS ===\")\n",
    "    print(f\"T1 = {T1}\")\n",
    "    print(f\"T2 = {T2}\")\n",
    "    \n",
    "    # Standard method\n",
    "    i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "    print(f\"\\nStandard result:\")\n",
    "    print(f\"i1 = {i1_std}\")\n",
    "    print(f\"i2 = {i2_std}\")\n",
    "    \n",
    "    # Fast numba method\n",
    "    i1_fast, i2_fast = fast_cartesian_numba(T1, T2)\n",
    "    print(f\"\\nNumba result:\")\n",
    "    print(f\"i1 = {i1_fast}\")\n",
    "    print(f\"i2 = {i2_fast}\")\n",
    "    \n",
    "    # Verify they're the same\n",
    "    print(f\"Results identical: {np.array_equal(i1_std, i1_fast) and np.array_equal(i2_std, i2_fast)}\")\n",
    "    \n",
    "    # Show lazy iteration\n",
    "    print(f\"\\nLazy iteration:\")\n",
    "    for i, (a, b) in enumerate(lazy_cartesian_iterator(T1, T2)):\n",
    "        print(f\"  Pair {i}: ({a}, {b})\")\n",
    "    \n",
    "    # Memory efficient examples\n",
    "    memory_efficient_examples()\n",
    "    \n",
    "    # Speed comparison\n",
    "    speed_comparison_demo()\n",
    "    \n",
    "    print(\"\\n=== RECOMMENDATIONS BY USE CASE ===\")\n",
    "    print(\"• Sequential access only: Use lazy_cartesian_iterator() - O(1) memory\")\n",
    "    print(\"• Large arrays, need full result: Use fast_cartesian_numba() - 2-10x faster\")\n",
    "    print(\"• Memory constrained: Use chunked_cartesian() - process in batches\")\n",
    "    print(\"• Direct operations: Use broadcasting - avoid materialization entirely\")\n",
    "    print(\"• Small arrays: Standard repeat+tile is fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd4f00cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([4, 5], dtype =float)\n",
    "\n",
    "x.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da901496",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@njit\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_key\u001b[39m(i, j, k, J, K):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i \u001b[38;5;241m*\u001b[39m J \u001b[38;5;241m*\u001b[39m K \u001b[38;5;241m+\u001b[39m j \u001b[38;5;241m*\u001b[39m K \u001b[38;5;241m+\u001b[39m k\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def encode_key(i, j, k, J, K):\n",
    "    return i * J * K + j * K + k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e469290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "share_envpy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
