{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5afd7c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i1 = np.array([1, 5, 3, 4])\n",
    "num_m1 = np.array([1, 1, 1, 1])\n",
    "val1 = np.array([0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "i2 = np.array([2, 7, 8])\n",
    "num_m2 = np.array([1, 1, 1])\n",
    "val2 = np.array([1, 2, 3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "set(num_m1) == set(num_m2) and len(set(num_m1)) == 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29335639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [1, 2, 3]\n",
    "list2 = [4, 5, 6]\n",
    "list1.extend(list2)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbc86b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 3, 4, 2, 7, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(i1, i2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "951ed9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val : [0.2 0.4 0.6 0.3 0.6 0.9 0.4 0.8 1.2 0.5 1.  1.5]\n",
      "val .shape :      (12,)\n",
      "i : [2 7 8 2 7 8 2 7 8 2 7 8]\n",
      "j :  [1 1 1 5 5 5 3 3 3 4 4 4]\n",
      "num_m : [1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "val = vectorized_operations_example(val1, val2, np.multiply)\n",
    "val = val.flatten()\n",
    "print(\"val :\", val)\n",
    "i_j = vectorized_operations_example(i2, i1, np.meshgrid)\n",
    "i_j = np.array(i_j).flatten()\n",
    "print(\"val .shape :     \", val.shape)\n",
    "print(\"i :\", i_j[:val.shape[0]])\n",
    "print(\"j : \", i_j[val.shape[0]:])\n",
    "i = i_j[:val.shape[0]]\n",
    "j = i_j[val.shape[0]:]\n",
    "num_m = np.broadcast_to(num_m1[:, np.newaxis], (len(num_m1), len(num_m2))).flatten()\n",
    "print(\"num_m :\", num_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfcdad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.append(i, 2)\n",
    "j = np.append(j, 1)\n",
    "num_m = np.append(num_m, 1)\n",
    "val = np.append(val, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e64cddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : [2 7 8 2 7 8 2 7 8 2 7 8 2]\n",
      "j : [1 1 1 5 5 5 3 3 3 4 4 4 1]\n",
      "i : [2 7 8 5 7 8 3 7 8 4 7 8 2]\n",
      "j : [1 1 1 2 5 5 2 3 3 2 4 4 1]\n",
      "T1_red : [2 3 4 5 7 7 7 7 8 8 8 8]\n",
      "T2_red : [1 2 2 2 1 3 4 5 1 3 4 5]\n",
      "T3_red : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "T4_red : [99.2  0.4  0.5  0.3  0.4  0.8  1.   0.6  0.6  1.2  1.5  0.9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: T1, T2, T3, T4 are 1D arrays of the same length\n",
    "# Combine T1, T2, T3 into a structured array of tuples\n",
    "print(\"i :\", i)\n",
    "print(\"j :\", j)\n",
    "i_ = np.where(i > j , i, j)\n",
    "j_ = np.where(i > j , j, i)\n",
    "print(\"i :\", i_)\n",
    "print(\"j :\", j_)\n",
    "keys = np.stack((i_, j_, num_m), axis=-1)\n",
    "\n",
    "# Get unique keys and inverse indices\n",
    "unique_keys, inverse = np.unique(keys, axis=0, return_inverse=True)\n",
    "\n",
    "# Sum T4 values for each unique key\n",
    "summed_T4 = np.bincount(inverse, weights=val)\n",
    "\n",
    "# Split unique keys back into T1, T2, T3\n",
    "T1_red, T2_red, T3_red = unique_keys.T\n",
    "T4_red = summed_T4\n",
    "\n",
    "print(\"T1_red :\", T1_red)\n",
    "print(\"T2_red :\", T2_red)\n",
    "print(\"T3_red :\", T3_red)\n",
    "print(\"T4_red :\", T4_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "207f4a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "383cd2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1 : [1 1 1 5 5 5 3 3 3 4 4 4]\n",
      "T2 : [6 7 8 6 7 8 6 7 8 6 7 8]\n",
      "val : [0.2 0.4 0.6 0.3 0.6 0.9 0.4 0.8 1.2 0.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "T1 = np.repeat(i1, len(i2))\n",
    "T2 = np.tile(i2, len(i1))\n",
    "val = np.repeat(val1, len(i2))* (np.tile(val2, len(i1)))\n",
    "\n",
    "print(\"T1 :\", T1)\n",
    "print(\"T2 :\", T2)\n",
    "print(\"val :\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e700c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ============ FASTER ALTERNATIVES ============\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "# ============ FASTER ALTERNATIVES ============\n",
    "\n",
    "def lazy_cartesian_iterator(T1, T2):\n",
    "    \"\"\"\n",
    "    FASTEST for sequential access - no memory allocation upfront.\n",
    "    Memory: O(1), Time per element: O(1)\n",
    "    \"\"\"\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            yield t1, t2\n",
    "\n",
    "def itertools_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Using itertools.product - very memory efficient.\n",
    "    \"\"\"\n",
    "    return itertools.product(T1, T2)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def numba_cartesian_fill(T1, T2, i1, i2):\n",
    "    \"\"\"\n",
    "    Numba-compiled version - much faster for large arrays.\n",
    "    Pre-allocate arrays and fill them with compiled code.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for i in range(len(T1)):\n",
    "        for j in range(len(T2)):\n",
    "            i1[idx] = T1[i]\n",
    "            i2[idx] = T2[j]\n",
    "            idx += 1\n",
    "\n",
    "def fast_cartesian_numba(T1, T2):\n",
    "    \"\"\"\n",
    "    Fastest for large arrays when you need materialized result.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    numba_cartesian_fill(T1, T2, i1, i2)\n",
    "    return i1, i2\n",
    "\n",
    "def broadcasting_indices(T1, T2):import numpy as np\n",
    "import itertools\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "# ============ FASTER ALTERNATIVES ============\n",
    "\n",
    "def lazy_cartesian_iterator(T1, T2):\n",
    "    \"\"\"\n",
    "    FASTEST for sequential access - no memory allocation upfront.\n",
    "    Memory: O(1), Time per element: O(1)\n",
    "    \"\"\"\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            yield t1, t2\n",
    "\n",
    "def itertools_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Using itertools.product - very memory efficient.\n",
    "    \"\"\"\n",
    "    return itertools.product(T1, T2)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def numba_cartesian_fill(T1, T2, i1, i2):\n",
    "    \"\"\"\n",
    "    Numba-compiled version - much faster for large arrays.\n",
    "    Pre-allocate arrays and fill them with compiled code.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    for i in range(len(T1)):\n",
    "        for j in range(len(T2)):\n",
    "            i1[idx] = T1[i]\n",
    "            i2[idx] = T2[j]\n",
    "            idx += 1\n",
    "\n",
    "def fast_cartesian_numba(T1, T2):\n",
    "    \"\"\"\n",
    "    Fastest for large arrays when you need materialized result.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    numba_cartesian_fill(T1, T2, i1, i2)\n",
    "    return i1, i2\n",
    "\n",
    "def broadcasting_indices(T1, T2):\n",
    "    \"\"\"\n",
    "    Use broadcasting with indices - avoids copying data.\n",
    "    Most memory efficient when you can work with indices.\n",
    "    \"\"\"\n",
    "    i_indices = np.arange(len(T1))[:, None]\n",
    "    j_indices = np.arange(len(T2))[None, :]\n",
    "    \n",
    "    # Return indices that can be used to access T1 and T2\n",
    "    return i_indices + np.zeros_like(j_indices), j_indices + np.zeros_like(i_indices)\n",
    "\n",
    "def chunked_cartesian(T1, T2, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Process Cartesian product in chunks - memory efficient for huge arrays.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    for i in range(0, len(T1), chunk_size):\n",
    "        chunk_T1 = T1[i:i+chunk_size]\n",
    "        i1_chunk = np.repeat(chunk_T1, len(T2))\n",
    "        i2_chunk = np.tile(T2, len(chunk_T1))\n",
    "        yield i1_chunk, i2_chunk\n",
    "\n",
    "def meshgrid_view_based(T1, T2):\n",
    "    \"\"\"\n",
    "    Use meshgrid but delay flattening - work with 2D views when possible.\n",
    "    \"\"\"\n",
    "    mesh1, mesh2 = np.meshgrid(T1, T2, indexing='ij')\n",
    "    return mesh1, mesh2  # Return 2D arrays instead of flattening\n",
    "\n",
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "# ============ SPECIALIZED FAST IMPLEMENTATIONS ============\n",
    "\n",
    "def fast_cartesian_memoryview(T1, T2):\n",
    "    \"\"\"\n",
    "    Using memory views for even faster access (when using Cython/Numba).\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Manual filling (would be faster in Cython)\n",
    "    idx = 0\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            i1[idx] = t1\n",
    "            i2[idx] = t2\n",
    "            idx += 1\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "def preallocated_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Pre-allocate arrays with correct dtype for better performance.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    \n",
    "    # Pre-allocate with specific dtypes\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Use numpy operations on pre-allocated arrays\n",
    "    i1[:] = np.repeat(T1, len(T2))\n",
    "    i2[:] = np.tile(T2, len(T1))\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "# ============ BENCHMARKING ============\n",
    "\n",
    "def benchmark_all_methods(T1, T2, iterations=100):\n",
    "    \"\"\"\n",
    "    Benchmark all methods comprehensively.\n",
    "    \"\"\"\n",
    "    methods = [\n",
    "        (\"Standard repeat+tile\", lambda: (np.repeat(T1, len(T2)), np.tile(T2, len(T1)))),\n",
    "        (\"Numba compiled\", lambda: fast_cartesian_numba(T1, T2)),\n",
    "        (\"Pre-allocated\", lambda: preallocated_cartesian(T1, T2)),\n",
    "        (\"Memory view style\", lambda: fast_cartesian_memoryview(T1, T2)),\n",
    "        (\"Meshgrid+flatten\", lambda: [x.flatten() for x in np.meshgrid(T1, T2, indexing='ij')]),\n",
    "    ]\n",
    "    \n",
    "    print(f\"Benchmarking with T1 size: {len(T1)}, T2 size: {len(T2)}\")\n",
    "    print(f\"Output size: {len(T1) * len(T2)}, Iterations: {iterations}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, method in methods:\n",
    "        # Warmup for Numba\n",
    "        if \"Numba\" in name:\n",
    "            method()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(iterations):\n",
    "            result = method()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results[name] = elapsed / iterations\n",
    "        print(f\"{name:20}: {elapsed/iterations:.6f}s per call\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def memory_efficient_examples():\n",
    "    \"\"\"\n",
    "    Show memory-efficient alternatives for different use cases.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MEMORY-EFFICIENT ALTERNATIVES ===\")\n",
    "    \n",
    "    T1 = np.arange(1000)\n",
    "    T2 = np.arange(2000)\n",
    "    \n",
    "    print(f\"Input sizes: T1={len(T1)}, T2={len(T2)}\")\n",
    "    print(f\"Full Cartesian product would need: {len(T1) * len(T2) * 8 / 1e6:.1f} MB\")\n",
    "    \n",
    "    print(\"\\n1. Lazy iteration (zero upfront memory):\")\n",
    "    lazy_iter = lazy_cartesian_iterator(T1[:10], T2[:10])\n",
    "    print(\"   First 3 pairs:\", [next(lazy_iter) for _ in range(3)])\n",
    "    \n",
    "    print(\"\\n2. Chunked processing:\")\n",
    "    chunk_gen = chunked_cartesian(T1[:100], T2[:100], chunk_size=50)\n",
    "    first_chunk = next(chunk_gen)\n",
    "    print(f\"   First chunk size: {len(first_chunk[0])}\")\n",
    "    \n",
    "    print(\"\\n3. Broadcasting for direct computation:\")\n",
    "    # Example: compute sum of all pairs without storing pairs\n",
    "    sum_matrix = vectorized_operations_example(T1[:10], T2[:10], np.add)\n",
    "    print(f\"   Sum matrix shape: {sum_matrix.shape}\")\n",
    "    print(f\"   Memory saved: {100 * (1 - sum_matrix.nbytes / (len(T1[:10]) * len(T2[:10]) * 2 * 8)):.1f}%\")\n",
    "\n",
    "def speed_comparison_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate speed improvements with different array sizes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SPEED COMPARISON ===\")\n",
    "    \n",
    "    sizes = [(100, 100), (500, 200), (1000, 100)]\n",
    "    \n",
    "    for t1_size, t2_size in sizes:\n",
    "        print(f\"\\nArray sizes: T1={t1_size}, T2={t2_size}\")\n",
    "        T1 = np.arange(t1_size)\n",
    "        T2 = np.arange(t2_size)\n",
    "        \n",
    "        # Standard method\n",
    "        start = time.time()\n",
    "        i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "        std_time = time.time() - start\n",
    "        \n",
    "        # Numba method\n",
    "        start = time.time()\n",
    "        i1_numba, i2_numba = fast_cartesian_numba(T1, T2)\n",
    "        numba_time = time.time() - start\n",
    "        \n",
    "        # Verify results are identical\n",
    "        identical = np.array_equal(i1_std, i1_numba) and np.array_equal(i2_std, i2_numba)\n",
    "        speedup = std_time / numba_time if numba_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  Standard: {std_time:.6f}s\")\n",
    "        print(f\"  Numba:    {numba_time:.6f}s\")\n",
    "        print(f\"  Speedup:  {speedup:.1f}x\")\n",
    "        print(f\"  Results identical: {identical}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with small arrays first\n",
    "    T1 = [1, 2]\n",
    "    T2 = [3, 4, 5]\n",
    "    \n",
    "    print(\"=== TESTING WITH SMALL ARRAYS ===\")\n",
    "    print(f\"T1 = {T1}\")\n",
    "    print(f\"T2 = {T2}\")\n",
    "    \n",
    "    # Standard method\n",
    "    i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "    print(f\"\\nStandard result:\")\n",
    "    print(f\"i1 = {i1_std}\")\n",
    "    print(f\"i2 = {i2_std}\")\n",
    "    \n",
    "    # Fast numba method\n",
    "    i1_fast, i2_fast = fast_cartesian_numba(T1, T2)\n",
    "    print(f\"\\nNumba result:\")\n",
    "    print(f\"i1 = {i1_fast}\")\n",
    "    print(f\"i2 = {i2_fast}\")\n",
    "    \n",
    "    # Verify they're the same\n",
    "    print(f\"Results identical: {np.array_equal(i1_std, i1_fast) and np.array_equal(i2_std, i2_fast)}\")\n",
    "    \n",
    "    # Show lazy iteration\n",
    "    print(f\"\\nLazy iteration:\")\n",
    "    for i, (a, b) in enumerate(lazy_cartesian_iterator(T1, T2)):\n",
    "        print(f\"  Pair {i}: ({a}, {b})\")\n",
    "    \n",
    "    # Memory efficient examples\n",
    "    memory_efficient_examples()\n",
    "    \n",
    "    # Speed comparison\n",
    "    speed_comparison_demo()\n",
    "    \n",
    "    print(\"\\n=== RECOMMENDATIONS BY USE CASE ===\")\n",
    "    print(\"• Sequential access only: Use lazy_cartesian_iterator() - O(1) memory\")\n",
    "    print(\"• Large arrays, need full result: Use fast_cartesian_numba() - 2-10x faster\")\n",
    "    print(\"• Memory constrained: Use chunked_cartesian() - process in batches\")\n",
    "    print(\"• Direct operations: Use broadcasting - avoid materialization entirely\")\n",
    "    print(\"• Small arrays: Standard repeat+tile is fine\"\n",
    "    \"\"\"\n",
    "    Use broadcasting with indices - avoids copying data.\n",
    "    Most memory efficient when you can work with indices.\n",
    "    \"\"\"\n",
    "    i_indices = np.arange(len(T1))[:, None]\n",
    "    j_indices = np.arange(len(T2))[None, :]\n",
    "    \n",
    "    # Return indices that can be used to access T1 and T2\n",
    "    return i_indices + np.zeros_like(j_indices), j_indices + np.zeros_like(i_indices)\n",
    "\n",
    "def chunked_cartesian(T1, T2, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Process Cartesian product in chunks - memory efficient for huge arrays.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    for i in range(0, len(T1), chunk_size):\n",
    "        chunk_T1 = T1[i:i+chunk_size]\n",
    "        i1_chunk = np.repeat(chunk_T1, len(T2))\n",
    "        i2_chunk = np.tile(T2, len(chunk_T1))\n",
    "        yield i1_chunk, i2_chunk\n",
    "\n",
    "def meshgrid_view_based(T1, T2):\n",
    "    \"\"\"\n",
    "    Use meshgrid but delay flattening - work with 2D views when possible.\n",
    "    \"\"\"\n",
    "    mesh1, mesh2 = np.meshgrid(T1, T2, indexing='ij')\n",
    "    return mesh1, mesh2  # Return 2D arrays instead of flattening\n",
    "\n",
    "def vectorized_operations_example(T1, T2, operation_func):\n",
    "    \"\"\"\n",
    "    Instead of creating full Cartesian product, apply operations directly.\n",
    "    Example: computing sum of all pairs without storing pairs.\n",
    "    \"\"\"\n",
    "    # Broadcasting for direct computation\n",
    "    T1_broadcast = T1[:, np.newaxis]\n",
    "    T2_broadcast = T2[np.newaxis, :]\n",
    "    \n",
    "    # Apply operation directly on broadcasted arrays\n",
    "    result = operation_func(T1_broadcast, T2_broadcast)\n",
    "    return result\n",
    "\n",
    "# ============ SPECIALIZED FAST IMPLEMENTATIONS ============\n",
    "\n",
    "def fast_cartesian_memoryview(T1, T2):\n",
    "    \"\"\"\n",
    "    Using memory views for even faster access (when using Cython/Numba).\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Manual filling (would be faster in Cython)\n",
    "    idx = 0\n",
    "    for t1 in T1:\n",
    "        for t2 in T2:\n",
    "            i1[idx] = t1\n",
    "            i2[idx] = t2\n",
    "            idx += 1\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "def preallocated_cartesian(T1, T2):\n",
    "    \"\"\"\n",
    "    Pre-allocate arrays with correct dtype for better performance.\n",
    "    \"\"\"\n",
    "    T1 = np.asarray(T1)\n",
    "    T2 = np.asarray(T2)\n",
    "    \n",
    "    total_size = len(T1) * len(T2)\n",
    "    \n",
    "    # Pre-allocate with specific dtypes\n",
    "    i1 = np.empty(total_size, dtype=T1.dtype)\n",
    "    i2 = np.empty(total_size, dtype=T2.dtype)\n",
    "    \n",
    "    # Use numpy operations on pre-allocated arrays\n",
    "    i1[:] = np.repeat(T1, len(T2))\n",
    "    i2[:] = np.tile(T2, len(T1))\n",
    "    \n",
    "    return i1, i2\n",
    "\n",
    "# ============ BENCHMARKING ============\n",
    "\n",
    "def benchmark_all_methods(T1, T2, iterations=100):\n",
    "    \"\"\"\n",
    "    Benchmark all methods comprehensively.\n",
    "    \"\"\"\n",
    "    methods = [\n",
    "        (\"Standard repeat+tile\", lambda: (np.repeat(T1, len(T2)), np.tile(T2, len(T1)))),\n",
    "        (\"Numba compiled\", lambda: fast_cartesian_numba(T1, T2)),\n",
    "        (\"Pre-allocated\", lambda: preallocated_cartesian(T1, T2)),\n",
    "        (\"Memory view style\", lambda: fast_cartesian_memoryview(T1, T2)),\n",
    "        (\"Meshgrid+flatten\", lambda: [x.flatten() for x in np.meshgrid(T1, T2, indexing='ij')]),\n",
    "    ]\n",
    "    \n",
    "    print(f\"Benchmarking with T1 size: {len(T1)}, T2 size: {len(T2)}\")\n",
    "    print(f\"Output size: {len(T1) * len(T2)}, Iterations: {iterations}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, method in methods:\n",
    "        # Warmup for Numba\n",
    "        if \"Numba\" in name:\n",
    "            method()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(iterations):\n",
    "            result = method()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        results[name] = elapsed / iterations\n",
    "        print(f\"{name:20}: {elapsed/iterations:.6f}s per call\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def memory_efficient_examples():\n",
    "    \"\"\"\n",
    "    Show memory-efficient alternatives for different use cases.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== MEMORY-EFFICIENT ALTERNATIVES ===\")\n",
    "    \n",
    "    T1 = np.arange(1000)\n",
    "    T2 = np.arange(2000)\n",
    "    \n",
    "    print(f\"Input sizes: T1={len(T1)}, T2={len(T2)}\")\n",
    "    print(f\"Full Cartesian product would need: {len(T1) * len(T2) * 8 / 1e6:.1f} MB\")\n",
    "    \n",
    "    print(\"\\n1. Lazy iteration (zero upfront memory):\")\n",
    "    lazy_iter = lazy_cartesian_iterator(T1[:10], T2[:10])\n",
    "    print(\"   First 3 pairs:\", [next(lazy_iter) for _ in range(3)])\n",
    "    \n",
    "    print(\"\\n2. Chunked processing:\")\n",
    "    chunk_gen = chunked_cartesian(T1[:100], T2[:100], chunk_size=50)\n",
    "    first_chunk = next(chunk_gen)\n",
    "    print(f\"   First chunk size: {len(first_chunk[0])}\")\n",
    "    \n",
    "    print(\"\\n3. Broadcasting for direct computation:\")\n",
    "    # Example: compute sum of all pairs without storing pairs\n",
    "    sum_matrix = vectorized_operations_example(T1[:10], T2[:10], np.add)\n",
    "    print(f\"   Sum matrix shape: {sum_matrix.shape}\")\n",
    "    print(f\"   Memory saved: {100 * (1 - sum_matrix.nbytes / (len(T1[:10]) * len(T2[:10]) * 2 * 8)):.1f}%\")\n",
    "\n",
    "def speed_comparison_demo():\n",
    "    \"\"\"\n",
    "    Demonstrate speed improvements with different array sizes.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== SPEED COMPARISON ===\")\n",
    "    \n",
    "    sizes = [(100, 100), (500, 200), (1000, 100)]\n",
    "    \n",
    "    for t1_size, t2_size in sizes:\n",
    "        print(f\"\\nArray sizes: T1={t1_size}, T2={t2_size}\")\n",
    "        T1 = np.arange(t1_size)\n",
    "        T2 = np.arange(t2_size)\n",
    "        \n",
    "        # Standard method\n",
    "        start = time.time()\n",
    "        i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "        std_time = time.time() - start\n",
    "        \n",
    "        # Numba method\n",
    "        start = time.time()\n",
    "        i1_numba, i2_numba = fast_cartesian_numba(T1, T2)\n",
    "        numba_time = time.time() - start\n",
    "        \n",
    "        # Verify results are identical\n",
    "        identical = np.array_equal(i1_std, i1_numba) and np.array_equal(i2_std, i2_numba)\n",
    "        speedup = std_time / numba_time if numba_time > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  Standard: {std_time:.6f}s\")\n",
    "        print(f\"  Numba:    {numba_time:.6f}s\")\n",
    "        print(f\"  Speedup:  {speedup:.1f}x\")\n",
    "        print(f\"  Results identical: {identical}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with small arrays first\n",
    "    T1 = [1, 2]\n",
    "    T2 = [3, 4, 5]\n",
    "    \n",
    "    print(\"=== TESTING WITH SMALL ARRAYS ===\")\n",
    "    print(f\"T1 = {T1}\")\n",
    "    print(f\"T2 = {T2}\")\n",
    "    \n",
    "    # Standard method\n",
    "    i1_std, i2_std = np.repeat(T1, len(T2)), np.tile(T2, len(T1))\n",
    "    print(f\"\\nStandard result:\")\n",
    "    print(f\"i1 = {i1_std}\")\n",
    "    print(f\"i2 = {i2_std}\")\n",
    "    \n",
    "    # Fast numba method\n",
    "    i1_fast, i2_fast = fast_cartesian_numba(T1, T2)\n",
    "    print(f\"\\nNumba result:\")\n",
    "    print(f\"i1 = {i1_fast}\")\n",
    "    print(f\"i2 = {i2_fast}\")\n",
    "    \n",
    "    # Verify they're the same\n",
    "    print(f\"Results identical: {np.array_equal(i1_std, i1_fast) and np.array_equal(i2_std, i2_fast)}\")\n",
    "    \n",
    "    # Show lazy iteration\n",
    "    print(f\"\\nLazy iteration:\")\n",
    "    for i, (a, b) in enumerate(lazy_cartesian_iterator(T1, T2)):\n",
    "        print(f\"  Pair {i}: ({a}, {b})\")\n",
    "    \n",
    "    # Memory efficient examples\n",
    "    memory_efficient_examples()\n",
    "    \n",
    "    # Speed comparison\n",
    "    speed_comparison_demo()\n",
    "    \n",
    "    print(\"\\n=== RECOMMENDATIONS BY USE CASE ===\")\n",
    "    print(\"• Sequential access only: Use lazy_cartesian_iterator() - O(1) memory\")\n",
    "    print(\"• Large arrays, need full result: Use fast_cartesian_numba() - 2-10x faster\")\n",
    "    print(\"• Memory constrained: Use chunked_cartesian() - process in batches\")\n",
    "    print(\"• Direct operations: Use broadcasting - avoid materialization entirely\")\n",
    "    print(\"• Small arrays: Standard repeat+tile is fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd4f00cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([4, 5], dtype =float)\n",
    "\n",
    "x.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da901496",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@njit\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_key\u001b[39m(i, j, k, J, K):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i \u001b[38;5;241m*\u001b[39m J \u001b[38;5;241m*\u001b[39m K \u001b[38;5;241m+\u001b[39m j \u001b[38;5;241m*\u001b[39m K \u001b[38;5;241m+\u001b[39m k\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def encode_key(i, j, k, J, K):\n",
    "    return i * J * K + j * K + k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ae31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e469290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue",
          "width": 2
         },
         "marker": {
          "color": "blue",
          "size": 6
         },
         "mode": "lines+markers",
         "name": "T1",
         "type": "scatter",
         "x": {
          "bdata": "AQIDBAUGBwgJCg==",
          "dtype": "i1"
         },
         "y": {
          "bdata": "AgQHCxAWHSUuOA==",
          "dtype": "i1"
         }
        },
        {
         "line": {
          "color": "red",
          "width": 2
         },
         "marker": {
          "color": "red",
          "size": 6
         },
         "mode": "lines+markers",
         "name": "T2",
         "type": "scatter",
         "x": {
          "bdata": "AQIDBAUGBwgJCg==",
          "dtype": "i1"
         },
         "y": {
          "bdata": "AQMGCg8VHCQtNw==",
          "dtype": "i1"
         }
        }
       ],
       "layout": {
        "height": 600,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.8)",
         "bordercolor": "rgba(0,0,0,0.2)",
         "borderwidth": 1,
         "x": 0.02,
         "y": 0.98
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Évolution de T1 et T2 en fonction de N"
        },
        "width": 800,
        "xaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "N"
         }
        },
        "yaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 1,
         "showgrid": true,
         "title": {
          "text": "Valeurs"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Exemple de données (remplacez par vos propres tableaux)\n",
    "N = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "T1 = np.array([2, 4, 7, 11, 16, 22, 29, 37, 46, 56])\n",
    "T2 = np.array([1, 3, 6, 10, 15, 21, 28, 36, 45, 55])\n",
    "\n",
    "# Création de la figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Ajout de la courbe T1\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=N,\n",
    "    y=T1,\n",
    "    mode='lines+markers',\n",
    "    name='T1',\n",
    "    line=dict(color='blue', width=2),\n",
    "    marker=dict(size=6, color='blue')\n",
    "))\n",
    "\n",
    "# Ajout de la courbe T2\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=N,\n",
    "    y=T2,\n",
    "    mode='lines+markers',\n",
    "    name='T2',\n",
    "    line=dict(color='red', width=2),\n",
    "    marker=dict(size=6, color='red')\n",
    "))\n",
    "\n",
    "# Configuration du layout\n",
    "fig.update_layout(\n",
    "    title='Évolution de T1 et T2 en fonction de N',\n",
    "    xaxis_title='N',\n",
    "    yaxis_title='Valeurs',\n",
    "    legend=dict(\n",
    "        x=0.02,\n",
    "        y=0.98,\n",
    "        bgcolor='rgba(255,255,255,0.8)',\n",
    "        bordercolor='rgba(0,0,0,0.2)',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Configuration des axes\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "# Affichage de la figure\n",
    "fig.show()\n",
    "\n",
    "# Optionnel : sauvegarder le graphique en HTML\n",
    "# fig.write_html(\"graphique_T1_T2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991908c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "share_envpy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
